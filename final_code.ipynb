{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### Reference From: https://www.kaggle.com/tarunpaparaju/plant-pathology-2020-eda-models"},{"metadata":{},"cell_type":"markdown","source":"<h2>Requirements</h2>"},{"metadata":{"trusted":false},"cell_type":"code","source":"#!pip install opencv-python","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#pip install tensorflow\n# !pip install --upgrade tensorflow\n# print(tf.__version__)\n# print(tf.keras.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q efficientnet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install plotly","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Data Description</h2>\n\nThe data which is used in this research is taken from the <b style=\"font-size: 20px\"><a href=\"https://www.kaggle.com/c/plant-pathology-2020-fgvc7/data\">plant-pathology-2020-fgvc7</a></b>\n\n<h3>1. Images</h3>\n<p>A folder containing the train and test images, in jpg format.</p>\n\n<h3>2. Train Data</h3><p>(train.csv)</p>\n\n<p>Data which is used to train the models is stored in this file</p>\n\n<h5>Columns:</h5>\n\n<p><b>image_id:</b> ID of the image which is located in images folder</p>\n<p><b>healthy</b> This column describes if the leaf is healthy or unhealthy if healthy it is marked as 1 else it is 0</p>\n<p><b>scab</b> This column describes if the leaf is diseased with Scab or not if the leaf is effected with Scab it is marked as 1 else it is 0</p>\n<p><b>rust</b> This column describes if the leaf is diseased with Rust or not if the leaf is effected with Rust it is marked as 1 else it is 0</p>\n<p><b>multiple_diseases</b> This column describes if the leaf is diseased with multiple diseases (like scab and rust) or not if the leaf is effected with multiple diseases it is marked as 1 else it is 0</p>\n\n<h3>3. Test Data</h3>\n\n<p>This data is used to test the model how effectively the model is working on unseen data</p>\n\n<h5>Columns:</h5>\n<p><b>image_id:</b> ID of the image which is located in images folder</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\nimport os\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport cv2\n\nfrom tqdm import tqdm\n# tqdm.pandas()\n\nimport tensorflow as tf\n\nimport efficientnet.tfkeras as efn\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\n\n\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score, confusion_matrix\n\nfrom kaggle_datasets import KaggleDatasets\n\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Load the Data</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"DIR_INPUT = '../input/plant-pathology-2020-fgvc7'\ntrain_data_path = DIR_INPUT + \"/train.csv\"\ntest_data_path = DIR_INPUT + \"/test.csv\"\nimages_path = DIR_INPUT + \"/images/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(train_data_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(test_data_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Exploring the Data</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rows and Columns in the data\n\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summary of the dataset: 1821 rows, 5 columns, no null values\n\nprint(train.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Description\n\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Structure of test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rows and Columns in the test data\n\ntest.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us find the duplicates in the dataset if any in train data\n\nbool_series = train[\"image_id\"].duplicated()\nlen(bool_series[bool_series].index.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us find the duplicates in the dataset if any in test data\n\nbool_series = train[\"image_id\"].duplicated()\nlen(bool_series[bool_series].index.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no duplicate images in both train and test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us find the missing values percentage of train data in column wise\n\nmissing_values = round(100*(train.isnull().sum()/len(train.index)),2)\nmissing_values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us find the missing values percentage of test data in column wise\n\nmissing_values = round(100*(test.isnull().sum()/len(test.index)),2)\nmissing_values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Data Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_data_distribution(column_name, labels = [], colours = [], xlabel='', ylabel=''):\n    plt.bar(labels, train[column_name].value_counts(), color=colours)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.annotate('{}\\n({:.4}%)'.format(train[column_name].value_counts()[0], \n                                             train[column_name].value_counts()[0]/train[column_name].count()*100),\n                 (0.20, 0.45), xycoords='axes fraction')\n    plt.annotate('{}\\n({:.4}%)'.format(train[column_name].value_counts()[1], \n                                             train[column_name].value_counts()[1]/train[column_name].count()*100),\n                 (0.70, 0.45), xycoords='axes fraction')\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Letus find the number of healthy and non-healthy leafs from data\nplot_data_distribution('healthy', labels=['Un-Healthy', 'Healthy'], colours=['#FF6666','#66FF66'], xlabel='Healthy', ylabel='Count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Letus find the number of Scab leaves and non-scab leaves from data\nplot_data_distribution('scab', labels=['Leaves without Scab', 'Leaves with Scab'], colours=['#66FF66', '#F27900'], xlabel='Scab', ylabel='Count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Letus find the number of Rust leaves and non-rust leaves from data\n\nplot_data_distribution('rust', labels=['Leaves without Rust', 'Leaves with Rust'], colours=['#66FF66', '#b7410e'], xlabel='Rust', ylabel='Count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Letus find the number of Multiple diseased leaves and leaves without multiple diseases from data\n\nplot_data_distribution('multiple_diseases', labels=['Leaves without multiple diseases', 'Leaves with multiple diseases'], colours=['#66FF66', '#b7410e'], xlabel='Multiple Diseases', ylabel='Count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of diseases \n\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.axis('equal')\nleaves = ['Healthy', 'Multiple Diseases', 'Rust', 'Scab']\nhealthy = len(train[train['healthy'] == 1])\nmultiple = len(train[train['multiple_diseases'] == 1])\nrust = len(train[train['rust'] == 1])\nscab = len(train[train['scab'] == 1])\ntotal_count = [healthy, multiple, rust, scab]\nax.pie(total_count, labels = leaves,autopct='%1.2f%%')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sample images from the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load images \ndef load_image(image_id): \n    image = cv2.imread(images_path + image_id + \".jpg\")\n    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = train[\"image_id\"][:500].apply(load_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function for loading the images form the dataset\ndef get_sample_images(image_type, skip = 0, take = 100):\n    \n    disease_cond_list = []\n    if image_type == 'healthy':\n        disease_cond_list = [1, 0, 0, 0]\n    elif image_type == 'multiple_diseases':\n        disease_cond_list = [0, 1, 0, 0]\n    elif image_type == 'rust':\n        disease_cond_list = [0, 0, 1, 0]\n    elif image_type == 'scab':\n        disease_cond_list = [0, 0, 0, 1]\n    else:\n        disease_cond_list = [1, 0, 0, 0]\n\n    if (len(disease_cond_list) > 1 ):\n        data = train[(train['healthy'] == disease_cond_list[0]) & (train['scab'] == disease_cond_list[1]) & (train['rust'] == disease_cond_list[2]) & (train['multiple_diseases'] == disease_cond_list[3])][skip:][:take]\n        \n        images = train_images.loc[list(data.index)]\n        cols, rows = 3, min([3, len(images)//3])\n\n        fig, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(30, rows*20/3))\n        for col in range(cols):\n            for row in range(rows):\n                ax[row, col].imshow(images.loc[images.index[row*3+col]])\n        plt.show()\n    else:\n        return None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Sample images of Healthy Leaves"},{"metadata":{"trusted":true},"cell_type":"code","source":"get_sample_images(\"healthy\", 3, 6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Sample images of leaves with multiple diseases"},{"metadata":{"trusted":true},"cell_type":"code","source":"get_sample_images(\"multiple_diseases\", 3, 6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Sample images of leaves with rust"},{"metadata":{"trusted":true},"cell_type":"code","source":"get_sample_images(\"rust\", 3, 6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Sample images of leaves with scab"},{"metadata":{"trusted":true},"cell_type":"code","source":"get_sample_images(\"scab\", 3, 6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding Duplicates\n\ndef get_duplicates(images):\n    for idx, i in enumerate(images):\n        \n        image1 = cv2.imread(images_path + i[0] + \".jpg\")\n        image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n        \n        image2 = cv2.imread(images_path + i[1] + \".jpg\")\n        image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n        \n        fig = plt.figure(figsize=(10,10))\n        ax1 = fig.add_subplot(2,2,1)\n        ax1.set_title(i[0])\n        ax1.imshow(image1)\n        ax2 = fig.add_subplot(2,2,2)\n        ax2.set_title(i[1])\n        ax2.imshow(image2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_duplicates(np.array([['Train_379', 'Train_1173'], ['Test_683', 'Test_1691'], ['Test_570', 'Test_1212']]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train.loc[train.image_id != 'Train_1173']\ntest_df = test.loc[(test.image_id != 'Test_1691') & (test.image_id != 'Test_1212')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_sample = GCS_DS_PATH + '/images/Train_1307.jpg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_file(fileName, label=None):\n    bits = tf.io.read_file(fileName)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    if label is None:\n        return image\n    else:\n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(read_file(image_sample))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def image_brightness(image, label=None, brightness=0.2):\n    image = read_file(image)\n    image = tf.image.random_brightness(image, brightness)\n    if label is None:\n        return image\n    else:\n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image_brightness(image_sample))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def image_flipping(image, label=None, flip_type='left_right'):\n    image = read_file(image)\n    if flip_type == 'left_right':\n        image = tf.image.random_flip_left_right(image)\n    elif flip_type == 'up_down':\n        image = tf.image.random_flip_up_down(image)\n    else:\n        image = image\n    return image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preparing the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def map_image_with_path(image):\n    return GCS_DS_PATH + '/images/' + image + '.jpg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_paths = test.image_id.apply(map_image_with_path).values\ntrain_paths = train.image_id.apply(map_image_with_path).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = train[['healthy', 'multiple_diseases', 'rust', 'scab']].values\ntrain_paths, valid_paths, train_labels, valid_labels = train_test_split(train_paths, labels, test_size=0.15, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The number of training data : \", train_paths.shape[0])\nprint(\"The number of validation data : \", valid_paths.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Setup TPU Config"},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    print('Connected to TPU')\nelse:\n    print(\"Not connected to a TPU runtime. Using CPU/GPU strategy\")\n    strategy = tf.distribute.MirroredStrategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 16 * strategy.num_replicas_in_sync\nIMG_SIZE = 600\nEPOCHS = 25 # @param {type: \"slider\", min:10, max:100}\nSTEPS_PER_EPOCH = train_labels.shape[0] // BATCH_SIZE\nnb_classes = train_labels.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR_START = 0.00001\nLR_MAX = 0.0005\nLR_MIN = 0.00001\nLR_RAMPUP_EPOCHS = 5\nLR_SUSTAIN_EPOCHS = 1\nLR_EXP_DECAY = .8\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n    \nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\n\nrng = [i for i in range(EPOCHS)]\ny = [lrfn(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(filename, label=None, image_size=(IMG_SIZE, IMG_SIZE)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, image_size)\n    if label is None:\n        return image\n    else:\n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_augmentation(image, label=None):\n    image = tf.image.rot90(image,k=np.random.randint(4))\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    \n    if label is None:\n        return image\n    else:\n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_paths, train_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augmentation, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(IMG_SIZE)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((valid_paths, valid_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_paths)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EfficientNet - B7"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_efficientnet_model(weights='imagenet'):\n    with strategy.scope():\n        en =efn.EfficientNetB7(input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=weights, include_top=False)\n        en.trainable = True\n\n        model = tf.keras.Sequential([\n            en,\n            tf.keras.layers.GlobalAveragePooling2D(),\n            tf.keras.layers.Dense(train_labels.shape[1], activation='softmax')\n        ])\n        model.compile(optimizer='adam',\n            loss = 'categorical_crossentropy',\n            metrics=['categorical_accuracy']\n        )\n        print(model.summary())\n        return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelB7 = build_efficientnet_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tf.keras.utils.model_to_dot(Model(model.layers[0].input, model.layers[0].layers[11].output), dpi=70).create(prog='dot', format='svg')\ntf.keras.utils.plot_model(\n    Model(modelB7.layers[0].input, modelB7.layers[0].layers[11].output),\n    show_shapes=True,\n    show_layer_names=True,\n    rankdir=\"TB\",\n    expand_nested=True,\n    dpi=80,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# checkpoint=tf.keras.callbacks.ModelCheckpoint(f\"Enet_model.h5\", monitor='val_categorical_accuracy', verbose=1, save_best_only=True,\n#        save_weights_only=True,mode='max')\n\nhistoryB7 = modelB7.fit(\n    train_dataset,\n    epochs=EPOCHS,\n    validation_data=valid_dataset, \n    verbose=1,\n    callbacks=[lr_callback],\n    steps_per_epoch=STEPS_PER_EPOCH,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_training(params, title, ylabel, xlabel, legend=[]):\n    plt.plot(params[0])\n    plt.plot(params[1])\n    plt.title(title)\n    plt.ylabel(ylabel)\n    plt.xlabel(xlabel)\n    plt.legend(legend, loc=\"lower right\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_training(\n    [historyB7.history[\"loss\"], historyB7.history[\"val_loss\"]],\n    \"Loss\",\n    \"loss\",\n    \"epoch\",\n    [\"train\", \"validation\"]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_training(\n    [historyB7.history[\"categorical_accuracy\"], historyB7.history[\"val_categorical_accuracy\"]],\n    \"model accuracy\",\n    \"accuracy\",\n    \"epoch\",\n    [\"train\", \"validation\"]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.load_weights(\"../input/%s/best_weight.h5\" % (os.listdir('../input')[0]))\nprint(\"The Accuracy on the Validation data : {:.2f}%\".format(100 * modelB7.evaluate_generator(valid_dataset, verbose = 1)[-1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictedB7 = modelB7.predict(test_dataset,verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Sample Predicted Images EfficientNet"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_efficient(img):\n    image = load_image(img)\n    img_cv = cv2.resize(image/255.0, (IMG_SIZE, IMG_SIZE)).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n    \n    preds = modelB7.layers[2](modelB7.layers[1](modelB7.layers[0](img_cv))).numpy()[0]\n\n    if list.index(preds.tolist(), max(preds)) == 0:\n        pred = [1, 0, 0, 0]\n    if list.index(preds.tolist(), max(preds)) == 1:\n        pred = [0, 1, 0, 0]\n    if list.index(preds.tolist(), max(preds)) == 2:\n        pred = [0, 0, 1, 0]\n    if list.index(preds.tolist(), max(preds)) == 3:\n        pred = [0, 0, 0, 1]\n\n    variables = ['Healthy', 'Multiple Diseases', 'Rust', 'Scab'] \n\n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(11, 3))\n    \n    axes[0].imshow(load_image(img))\n    axes[0].set_title(img)\n    axes[1].bar(variables, pred, color=['#66FF66', '#F27900', '#b7410e', '#cc9966'])\n    axes[1].set_title(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_efficient(test['image_id'][0])\npredict_efficient(test['image_id'][2])\npredict_efficient(test['image_id'][3])\npredict_efficient(test['image_id'][966])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Efficientnet Noisy Student"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelNoisy = build_efficientnet_model('noisy-student')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# checkpoint=tf.keras.callbacks.ModelCheckpoint(f\"Enet_model.h5\", monitor='val_categorical_accuracy', verbose=1, save_best_only=True,\n#        save_weights_only=True,mode='max')\n\nhistoryB7 = modelNoisy.fit(\n    train_dataset, \n    epochs=EPOCHS,\n    validation_data=valid_dataset, \n    verbose=1, \n    callbacks=[lr_callback],\n    steps_per_epoch=STEPS_PER_EPOCH,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_training(\n    [historyB7.history[\"loss\"], historyB7.history[\"val_loss\"]],\n    \"Loss\",\n    \"loss\",\n    \"epoch\",\n    [\"train\", \"validation\"]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_training(\n    [historyB7.history[\"categorical_accuracy\"], historyB7.history[\"val_categorical_accuracy\"]],\n    \"model accuracy\",\n    \"accuracy\",\n    \"epoch\",\n    [\"train\", \"validation\"]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictedB7Noisy = modelNoisy.predict(test_dataset,verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### DenseNet"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_densenet_model(weights='imagenet'):\n    with strategy.scope():\n        dn = DenseNet121(input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=weights, include_top=False)\n        dn.trainable = True\n\n        model = tf.keras.Sequential([\n            dn,\n            tf.keras.layers.GlobalAveragePooling2D(),\n            tf.keras.layers.Dense(train_labels.shape[1], activation='softmax')\n        ])\n        model.compile(optimizer='adam',\n            loss = 'categorical_crossentropy',\n            metrics=['categorical_accuracy']\n        )\n        print(model.summary())\n        return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_dense = build_densenet_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.utils.plot_model(\n    Model(model_dense.layers[0].input, model_dense.layers[0].layers[13].output),\n    show_shapes=True,\n    show_layer_names=True,\n    rankdir=\"TB\",\n    expand_nested=True,\n    dpi=65,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# checkpoint=tf.keras.callbacks.ModelCheckpoint(f\"Enet_model.h5\", monitor='val_categorical_accuracy', verbose=1, save_best_only=True,\n#        save_weights_only=True,mode='max')\n\nhistoryDense = model_dense.fit(\n    train_dataset, \n    epochs=EPOCHS, \n    validation_data=valid_dataset, \n    verbose=1, \n    callbacks=[lr_callback],\n    steps_per_epoch=STEPS_PER_EPOCH,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_training(\n    [historyDense.history[\"loss\"], historyDense.history[\"val_loss\"]],\n    \"Loss\",\n    \"loss\",\n    \"epoch\",\n    [\"train\", \"validation\"]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_training(\n    [historyDense.history[\"categorical_accuracy\"], historyDense.history[\"val_categorical_accuracy\"]],\n    \"model accuracy\",\n    \"accuracy\",\n    \"epoch\",\n    [\"train\", \"validation\"]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictDense = model_dense.predict(test_dataset, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Predict Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_densenet(img):\n    image = load_image(img)\n    img_cv = cv2.resize(image/255.0, (IMG_SIZE, IMG_SIZE)).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n    \n    preds = model_dense.layers[2](model_dense.layers[1](model_dense.layers[0](img_cv))).numpy()[0]\n\n    if list.index(preds.tolist(), max(preds)) == 0:\n        pred = [1, 0, 0, 0]\n    if list.index(preds.tolist(), max(preds)) == 1:\n        pred = [0, 1, 0, 0]\n    if list.index(preds.tolist(), max(preds)) == 2:\n        pred = [0, 0, 1, 0]\n    if list.index(preds.tolist(), max(preds)) == 3:\n        pred = [0, 0, 0, 1]\n\n    variables = ['Healthy', 'Multiple Diseases', 'Rust', 'Scab'] \n\n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(11, 3))\n    \n    axes[0].imshow(load_image(img))\n    axes[0].set_title(img)\n    axes[1].bar(variables, pred, color=['#66FF66', '#F27900', '#b7410e', '#cc9966'])\n    axes[1].set_title(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_densenet(test['image_id'][0])\npredict_densenet(test['image_id'][2])\npredict_densenet(test['image_id'][3])\npredict_densenet(test['image_id'][966])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}